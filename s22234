from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.base import BaseEstimator, TransformerMixin
from sklearn.metrics import mean_squared_error, mean_absolute_error, make_scorer, mean_poisson_deviance
import xgboost as xgb
from typing import List, Dict, Tuple, Any, Optional
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import joblib
import warnings
from datetime import datetime

try:
    from skopt import gp_minimize
    from skopt.space import Real, Integer
    from skopt.utils import use_named_args
except ImportError as e:
    raise ImportError(
        "scikit-optimize is required for this frequency model. "
        "Install with: pip install scikit-optimize"
    ) from e

warnings.filterwarnings('ignore')


def neg_poisson_deviance_scorer(y_true, y_pred):
    """Sklearn scorer for negative Poisson deviance"""
    return -mean_poisson_deviance(y_true, y_pred)


try:
    from sklearn.metrics import get_scorer
    poisson_scorer = get_scorer('neg_mean_poisson_deviance')
    print("Using sklearn's built-in 'neg_mean_poisson_deviance' scorer")
except (ValueError, KeyError):
    poisson_scorer = make_scorer(neg_poisson_deviance_scorer, greater_is_better=True)
    print("Using custom negative Poisson deviance scorer")


class FeatureFilter(BaseEstimator, TransformerMixin):
    """Conservative feature filtering - same as severity model"""
    
    def __init__(self, min_sample_ratio=0.01, min_samples=100):  # ✅ Conservative like R
        self.min_sample_ratio = min_sample_ratio
        self.min_samples = min_samples
        self.features_to_keep_ = None
    
    def fit(self, X, y=None):
        X_df = pd.DataFrame(X) if not isinstance(X, pd.DataFrame) else X
        min_required = max(self.min_samples, len(X_df) * self.min_sample_ratio)
        self.features_to_keep_ = X_df.apply(lambda x: x.gt(0).sum() >= min_required, axis=0)
        
        filtered_count = len(X_df.columns) - self.features_to_keep_.sum()
        if filtered_count > 0:
            print(f"FeatureFilter: Filtered out {filtered_count} noisy features (R-style conservative)")
            
        return self
    
    def transform(self, X):
        if self.features_to_keep_ is None:
            raise ValueError("FeatureFilter not fitted yet")
        X_df = pd.DataFrame(X) if not isinstance(X, pd.DataFrame) else X
        return X_df.loc[:, self.features_to_keep_].values
    
    def get_feature_names_out(self, input_features=None):
        if self.features_to_keep_ is None:
            raise ValueError("FeatureFilter not fitted yet")
        if input_features is None:
            return [f"feature_{i}" for i in range(self.features_to_keep_.sum())]
        else:
            return [name for name, keep in zip(input_features, self.features_to_keep_) if keep]


class ConservativeFrequencyModelConfig:
    """Conservative configuration matching R's proven frequency parameters"""
    EARLY_STOPPING_ROUNDS = 50
    N_TRIALS_DEFAULT = 30  # ✅ Conservative number of trials
    RANDOM_STATE = 12
    TRAIN_SIZE = 0.7
    
    # ✅ CONSERVATIVE RANGES AROUND R'S PROVEN FREQUENCY VALUES
    PARAM_DIMENSIONS = [
        Integer(3, 5, name='max_depth'),              # ✅ R uses 4, allow 3-5
        Real(0.08, 0.12, name='eta'),                # ✅ R uses 0.1, narrow range around it  
        Real(0.55, 0.7, name='subsample'),           # ✅ R uses 0.6, narrow range around it
        Real(0.6, 0.7, name='colsample_bytree'),     # ✅ R uses 0.65, narrow range around it
        Real(1.0, 1.3, name='min_child_weight'),     # ✅ R uses 1.1, narrow range around it
        Real(0.0, 0.1, name='gamma'),                # ✅ R uses 0.05, light regularization only
        Real(0.6, 1.0, name='max_delta_step')        # ✅ Conservative stabilization
    ]


class ConservativeFrequencyModel:
    """Conservative frequency model using R's proven parameter philosophy"""
    
    def __init__(self, config: Optional[ConservativeFrequencyModelConfig] = None):
        self.config = config or ConservativeFrequencyModelConfig()
        self.random_state = self.config.RANDOM_STATE
        self.model = None
        self.preprocessor = None  
        self.feature_names = None
        self.target_feature = "NUM_LOSSES"
        self.objective = "count:poisson"              # ✅ Same as R
        self.eval_metric = "poisson-nloglik"          # ✅ Better than R's rmsle for Poisson
        self.monotone_constraints = None
        self.best_params = None
        self.evaluation_results = None
        self.training_metadata = {}

    def load_csv_data(self, policy_file: str, account_file: str, claims_file: str) -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:
        """Load CSV files for frequency modeling"""
        policy_list_all = pd.read_csv(policy_file)
        account_list = pd.read_csv(account_file)
        account_list = account_list.rename(columns={col: col.upper() for col in account_list.columns})
        claims_list = pd.read_csv(claims_file)
        return policy_list_all, account_list, claims_list

    def validate_features(self, data: pd.DataFrame, required_features: List[str]):
        """Validate all required features are present"""
        missing_features = set(required_features) - set(data.columns)
        if missing_features:
            raise ValueError(
                f"Missing required features: {missing_features}\n"
                f"Available features: {list(data.columns)}"
            )

    def create_random_splits(self, X: pd.DataFrame, y: pd.Series):
        """Create random splits like R (70% train, 30% validation)"""
        X_train, X_val, y_train, y_val = train_test_split(
            X, y, 
            test_size=(1 - self.config.TRAIN_SIZE), 
            random_state=self.random_state,
            stratify=None  # ✅ Same as R - no stratification
        )
        print(f"Conservative frequency splits (matching R):")
        print(f"  Train: {len(X_train):,} accounts, mean frequency: {y_train.mean():.3f}")
        print(f"  Validation: {len(X_val):,} accounts, mean frequency: {y_val.mean():.3f}")
        return X_train, X_val, y_train, y_val

    def prepare_features(self, X_data: pd.DataFrame) -> pd.DataFrame:
        """Same feature preparation as severity model"""
        data = X_data.copy()
        
        # Handle HIST_LR_3YEAR same as R and severity
        if "HIST_LR_3YEAR" in data.columns:
            data["HIST_LR_3YEAR"] = data["HIST_LR_3YEAR"].apply(
                lambda x: np.nan if pd.isna(x) else 1 if x > 1 else x
            )
        
        # Convert objects to categories
        for col in data.select_dtypes(include=['object']).columns:
            data[col] = data[col].astype('category')
        
        return data
    
    def create_preprocessor(self, non_ohe_features: List[str], ohe_features: List[str]) -> Pipeline:
        """Same preprocessing pipeline as severity model"""
        column_transformer = ColumnTransformer(
            transformers=[
                ('num', 'passthrough', [f.upper() for f in non_ohe_features]),
                ('cat', OneHotEncoder(sparse_output=False, drop=None, handle_unknown='ignore'), 
                 [f.upper() for f in ohe_features])
            ],
            remainder='drop'
        )
        
        pipeline = Pipeline([
            ('preprocessor', column_transformer),
            ('feature_filter', FeatureFilter())  # ✅ Conservative 100+ samples filtering
        ])
        
        return pipeline

    def create_monotone_constraints(self, feature_names: List[str]) -> str:
        """Same monotone constraints as severity model"""
        constraints = []
        for col in feature_names:
            if "A. Below" in col:
                constraints.append("-1")
            elif any(x in col for x in ["B. From ", "C. Over", "D. Unknown", "LR_3YEAR"]):
                constraints.append("1")
            else:
                constraints.append("0")
        constraint_string = f"({','.join(constraints)})"
        
        n_increasing = constraints.count("1")
        n_decreasing = constraints.count("-1")
        n_none = constraints.count("0")
        print(f"Frequency monotone constraints: {n_increasing} increasing, {n_decreasing} decreasing, {n_none} unconstrained")
        
        return constraint_string

    def optimize_hyperparameters(self, X_train: np.ndarray, y_train: np.ndarray, 
                                X_val: np.ndarray, y_val: np.ndarray,
                                n_trials: int = 30) -> Tuple[Dict[str, Any], float]:
        """Conservative GP optimization using R's proven parameter ranges"""
        
        print(f"Starting Conservative Frequency Optimization ({n_trials} trials)...")
        print("Using conservative ranges around R's proven frequency values:")
        print("  R frequency: eta=0.1, max_depth=4, subsample=0.6, colsample_bytree=0.65")
        print("  Python ranges: narrow bands around these proven values")
        
        @use_named_args(self.config.PARAM_DIMENSIONS)
        def objective(**params):
            try:
                # ✅ Use R's proven base parameters + optimized variations
                model_params = {
                    "objective": self.objective,
                    "booster": 'gbtree',
                    "tree_method": 'exact',                    # ✅ Same as R
                    "monotone_constraints": self.monotone_constraints,
                    "early_stopping_rounds": self.config.EARLY_STOPPING_ROUNDS,
                    "eval_metric": self.eval_metric,
                    "random_state": self.random_state,
                    "seed": self.random_state,
                    "n_estimators": 1000,                      # ✅ More rounds like R's 10000
                    "validate_parameters": True,
                    **params  # ✅ Conservative parameter variations
                }
                
                model = xgb.XGBRegressor(**model_params)
                model.fit(
                    X_train, y_train,
                    eval_set=[(X_train, y_train), (X_val, y_val)],
                    verbose=False
                )
                
                y_pred = model.predict(X_val)
                # Use Poisson deviance for frequency evaluation (better than RMSE)
                deviance = mean_poisson_deviance(y_val, y_pred)
                
                return deviance
                
            except Exception as e:
                print(f"Error in frequency objective function: {e}")
                return 999999
        
        # Conservative Gaussian Process optimization
        result = gp_minimize(
            func=objective,
            dimensions=self.config.PARAM_DIMENSIONS,
            n_calls=n_trials,
            n_initial_points=10,
            random_state=self.random_state,
            verbose=True
        )
        
        best_params = {}
        for i, param_name in enumerate([dim.name for dim in self.config.PARAM_DIMENSIONS]):
            best_params[param_name] = result.x[i]
        
        best_score = result.fun
        
        print(f"Conservative frequency optimization complete! Best score: {best_score:.6f}")
        print("Best frequency parameters found:")
        for param, value in best_params.items():
            if isinstance(value, float):
                print(f"  {param}: {value:.4f}")
            else:
                print(f"  {param}: {value}")
        
        return best_params, best_score

    def train_model(self, account_data: pd.DataFrame,
                   non_ohe_features: List[str],
                   ohe_features: List[str],
                   n_trials: int = None) -> Dict[str, Any]:
        """Train conservative frequency model using R's philosophy"""
        
        n_trials = n_trials or self.config.N_TRIALS_DEFAULT
        start_time = datetime.now()
        print("="*60)
        print("STARTING CONSERVATIVE FREQUENCY MODEL TRAINING")
        print("="*60)
        
        self.training_metadata = {
            'start_time': start_time.isoformat(),
            'n_trials': n_trials,
            'optimization_method': 'Conservative Gaussian Process around R values',
            'approach': 'R-matched conservative frequency modeling',
            'features': {
                'non_ohe': non_ohe_features,
                'ohe': ohe_features
            }
        }
        
        # 1. Prepare target and features
        target_col = self.target_feature if self.target_feature in account_data.columns else self.target_feature.lower()
        
        print("Step 1: Preparing frequency data (account-level)...")
        account_data_upper = account_data.rename(columns={col: col.upper() for col in account_data.columns})
        target_col_upper = target_col.upper()
        
        X = account_data_upper.drop(columns=[target_col_upper])
        y = account_data_upper[target_col_upper]
        
        print(f"Frequency data prepared:")
        print(f"  X (features): {X.shape}")
        print(f"  y (target): {y.shape}")
        print(f"  Mean frequency: {y.mean():.3f}")
        print(f"  Zero frequency accounts: {(y == 0).sum()}/{len(y)} ({100*(y == 0).mean():.1f}%)")
        
        # 2. Create splits like R
        print("Step 2: Creating conservative splits (matching R approach)...")
        X_train, X_val, y_train, y_val = self.create_random_splits(X, y)
        
        # 3. Feature preparation
        print("Step 3: Applying feature preparation...")
        X_train_prepared = self.prepare_features(X_train)
        X_val_prepared = self.prepare_features(X_val)
        
        # 4. Preprocessing pipeline
        print("Step 4: Creating conservative preprocessing pipeline...")
        self.preprocessor = self.create_preprocessor(non_ohe_features, ohe_features)
        
        all_features = [f.upper() for f in non_ohe_features + ohe_features]
        self.validate_features(X_train_prepared, all_features)
        self.validate_features(X_val_prepared, all_features)
        
        X_train_features = X_train_prepared[all_features]
        X_train_processed = self.preprocessor.fit_transform(X_train_features)
        
        X_val_features = X_val_prepared[all_features]
        X_val_processed = self.preprocessor.transform(X_val_features)
        
        # Get feature names
        column_transformer = self.preprocessor.named_steps['preprocessor']
        raw_feature_names = column_transformer.get_feature_names_out()
        feature_filter = self.preprocessor.named_steps['feature_filter']
        self.feature_names = feature_filter.get_feature_names_out(raw_feature_names)
        
        print(f"Features after transformation: {len(raw_feature_names)}")
        print(f"Features after conservative filtering (100+ samples): {len(self.feature_names)}")
        
        # 5. Monotone constraints
        print("Step 5: Creating monotone constraints...")
        self.monotone_constraints = self.create_monotone_constraints(self.feature_names)
        
        # 6. Conservative optimization
        print("Step 6: Conservative frequency hyperparameter optimization...")
        print("Using narrow ranges around R's proven frequency values:")
        for dim in self.config.PARAM_DIMENSIONS:
            print(f"  {dim.name}: {dim}")
        
        self.best_params, best_score = self.optimize_hyperparameters(
            X_train_processed, y_train.values, 
            X_val_processed, y_val.values, 
            n_trials
        )
        
        # 7. Train final model
        print("Step 7: Training final conservative frequency model...")
        
        final_params = {
            "objective": self.objective,
            "eval_metric": self.eval_metric,
            "booster": "gbtree",
            "tree_method": "exact",
            "monotone_constraints": self.monotone_constraints,
            "early_stopping_rounds": self.config.EARLY_STOPPING_ROUNDS,
            "validate_parameters": True,
            "random_state": self.random_state,
            "seed": self.random_state,
            "n_estimators": 1000  # ✅ Conservative like R
        }
        final_params.update(self.best_params)
        
        self.model = xgb.XGBRegressor(**final_params)
        
        print("Training final frequency model with R-inspired conservative parameters...")
        self.model.fit(
            X_train_processed, y_train,
            eval_set=[(X_train_processed, y_train), (X_val_processed, y_val)],
            verbose=50
        )
        
        best_iteration = self.model.best_iteration if hasattr(self.model, 'best_iteration') else len(self.model.get_booster().get_dump())
        print(f"Final conservative frequency model: {best_iteration} trees, best score: {best_score:.6f}")
        
        # 8. Evaluation
        print("Step 8: Evaluating conservative frequency model...")
        val_predictions = self.model.predict(X_val_processed)
        self.evaluation_results = self.comprehensive_evaluation(
            X_val_prepared, y_val.values, val_predictions
        )
        
        end_time = datetime.now()
        self.training_metadata.update({
            'end_time': end_time.isoformat(),
            'training_duration': str(end_time - start_time),
            'best_iteration': best_iteration,
            'best_score': best_score,
            'xgboost_version': xgb.__version__,
            'total_features': len(self.feature_names),
            'r_comparison': 'Conservative ranges around R proven values'
        })
        
        print(f"\nConservative frequency training completed in {end_time - start_time}")
        print("="*60)
        
        return {
            "model": self.model,
            "best_params": self.best_params,
            "best_score": best_score,
            "feature_names": self.feature_names,
            "preprocessor": self.preprocessor,
            "evaluation_results": self.evaluation_results,
            "X_train": X_train, "y_train": y_train,
            "X_val": X_val, "y_val": y_val,
            "training_metadata": self.training_metadata
        }

    def predict(self, new_data: pd.DataFrame, feature_columns: List[str]) -> np.ndarray:
        """Make frequency predictions"""
        if self.model is None:
            raise ValueError("Model not trained yet. Call train_model() first.")
        if self.preprocessor is None:
            raise ValueError("Preprocessing pipeline not fitted.")
        
        required_features = [f.upper() for f in feature_columns]
        self.validate_features(new_data, required_features)
        
        X = new_data[required_features]
        X_processed = self.preprocessor.transform(X)
        
        return self.model.predict(X_processed)

    def comprehensive_evaluation(self, test_features: pd.DataFrame, y_test: np.ndarray, predictions: np.ndarray) -> Dict[str, Any]:
        """Comprehensive frequency evaluation metrics"""
        
        basic_metrics = {
            'poisson_deviance': mean_poisson_deviance(y_test, predictions),
            'mae': mean_absolute_error(y_test, predictions),
            'rmse': np.sqrt(mean_squared_error(y_test, predictions)),
            'mean_actual_freq': y_test.mean(),
            'mean_predicted_freq': predictions.mean(),
            'freq_ratio': predictions.mean() / y_test.mean() if y_test.mean() > 0 else np.nan,
            'n_test_accounts': len(y_test),
            'zero_claims_actual': (y_test == 0).sum(),
            'zero_claims_predicted': (predictions < 0.5).sum()
        }
        
        # Distribution comparison
        actual_dist = pd.Series(y_test).value_counts().sort_index()
        pred_dist = pd.Series(np.round(predictions)).value_counts().sort_index()
        
        all_values = sorted(set(list(actual_dist.index) + list(pred_dist.index)))
        actual_dist = actual_dist.reindex(all_values, fill_value=0)
        pred_dist = pred_dist.reindex(all_values, fill_value=0)
        
        distribution_comparison = pd.DataFrame({
            'Actual_Count': actual_dist,
            'Predicted_Count': pred_dist,
            'Actual_Pct': actual_dist / len(y_test) * 100,
            'Predicted_Pct': pred_dist / len(predictions) * 100
        })
        
        return {
            'basic_metrics': basic_metrics,
            'distribution_comparison': distribution_comparison
        }

    def get_feature_importance(self, importance_type: str = 'weight') -> pd.DataFrame:
        """Get feature importance"""
        if self.model is None:
            raise ValueError("Model not trained yet.")
        
        if hasattr(self.model, 'get_booster'):
            importance = self.model.get_booster().get_score(importance_type=importance_type)
        else:
            importance_values = getattr(self.model, 'feature_importances_', None)
            if importance_values is None:
                raise ValueError("No feature importance available")
            importance = dict(zip(self.feature_names, importance_values))
        
        importance_df = pd.DataFrame([
            {'feature': k, 'importance': v}
            for k, v in importance.items()
        ])
        
        importance_df = importance_df.sort_values('importance', ascending=False)
        importance_df['rank'] = range(1, len(importance_df) + 1)
        importance_df['importance_pct'] = (importance_df['importance'] /
                                          importance_df['importance'].sum() * 100)
        
        return importance_df

    def save_model(self, filepath: str):
        """Save conservative frequency model"""
        if self.model is None:
            raise ValueError("Model not trained yet.")
        
        model_artifacts = {
            "model": self.model,
            "preprocessor": self.preprocessor,
            "feature_names": self.feature_names,
            "target_feature": self.target_feature,
            "objective": self.objective,
            "eval_metric": self.eval_metric,
            "monotone_constraints": self.monotone_constraints,
            "best_params": self.best_params,
            "evaluation_results": self.evaluation_results,
            "training_metadata": self.training_metadata,
            "config": self.config
        }
        
        joblib.dump(model_artifacts, filepath)
        print(f"Conservative frequency model saved to {filepath}")

    def load_model(self, filepath: str):
        """Load conservative frequency model"""
        model_artifacts = joblib.load(filepath)
        
        self.model = model_artifacts["model"]
        self.preprocessor = model_artifacts["preprocessor"]
        self.feature_names = model_artifacts["feature_names"]
        self.target_feature = model_artifacts["target_feature"]
        self.objective = model_artifacts["objective"]
        self.eval_metric = model_artifacts["eval_metric"]
        self.monotone_constraints = model_artifacts["monotone_constraints"]
        self.best_params = model_artifacts["best_params"]
        self.evaluation_results = model_artifacts.get("evaluation_results", None)
        self.training_metadata = model_artifacts.get("training_metadata", {})
        self.config = model_artifacts.get("config", ConservativeFrequencyModelConfig())
        
        print(f"Conservative frequency model loaded from {filepath}")

    def plot_feature_importance(self, max_features: int = 20):
        """Plot feature importance"""
        if self.model is None:
            raise ValueError("Model not trained yet.")
        
        fig, ax = plt.subplots(figsize=(10, 8))
        
        if hasattr(self.model, 'get_booster'):
            xgb.plot_importance(self.model.get_booster(), importance_type='weight',
                               max_num_features=max_features, ax=ax)
        else:
            importance_df = self.get_feature_importance()
            top_features = importance_df.head(max_features)
            ax.barh(range(len(top_features)), top_features['importance'])
            ax.set_yticks(range(len(top_features)))
            ax.set_yticklabels(top_features['feature'])
            ax.set_xlabel('Importance')
            
        plt.title("Conservative Frequency Model - Feature Importance")
        plt.tight_layout()
        return fig

    def print_evaluation_summary(self):
        """Print evaluation summary"""
        if self.evaluation_results is None:
            print("No evaluation results available. Train model first.")
            return
        
        print("="*60)
        print("CONSERVATIVE FREQUENCY MODEL EVALUATION SUMMARY")
        print("="*60)
        
        print("\nFREQUENCY PERFORMANCE METRICS:")
        for metric, value in self.evaluation_results['basic_metrics'].items():
            if isinstance(value, float):
                print(f"   {metric}: {value:.6f}")
            else:
                print(f"   {metric}: {value:,}")
        
        print("\nFREQUENCY DISTRIBUTION COMPARISON:")
        print(self.evaluation_results['distribution_comparison'].head(10))


def train_conservative_frequency_model(account_data: pd.DataFrame,
                                      non_ohe_features: List[str],
                                      ohe_features: List[str],
                                      n_trials: int = 30,
                                      save_path: Optional[str] = None) -> ConservativeFrequencyModel:
    """
    Train conservative frequency model using R's proven parameter philosophy
    """
    freq_model = ConservativeFrequencyModel()
    
    results = freq_model.train_model(
        account_data,
        non_ohe_features,
        ohe_features,
        n_trials=n_trials
    )
    
    freq_model.print_evaluation_summary()
    
    if save_path:
        freq_model.save_model(save_path)
        print(f"\nConservative frequency model saved to: {save_path}")
    
    return freq_model
